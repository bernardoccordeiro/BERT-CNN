{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\Users\\berna\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import set_random_seed\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "set_random_seed(2)\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Conv1D, Embedding, GlobalMaxPooling2D, GlobalMaxPooling1D, Dropout, Reshape, Input, Concatenate\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_str(string, TREC=False):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Every dataset is lower cased except for TREC\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)     \n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string) \n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string) \n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string) \n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string) \n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string) \n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string) \n",
    "    string = re.sub(r\",\", \" , \", string) \n",
    "    string = re.sub(r\"!\", \" ! \", string) \n",
    "    string = re.sub(r\"\\(\", \" \\( \", string) \n",
    "    string = re.sub(r\"\\)\", \" \\) \", string) \n",
    "    string = re.sub(r\"\\?\", \" \\? \", string) \n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)    \n",
    "    return string.strip() if TREC else string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_str_sst(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for the SST dataset\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)   \n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)    \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "set_random_seed(2)\n",
    "\n",
    "#MR Dataset\n",
    "train_neg = []\n",
    "train_pos = []\n",
    "with open('rt-polaritydata/rt-polarity.neg') as neg_r:\n",
    "    for line in neg_r.readlines():\n",
    "        train_neg.append(clean_str(line))\n",
    "with open('rt-polaritydata/rt-polarity.pos') as pos_r:\n",
    "    for line in pos_r.readlines():\n",
    "        train_pos.append(clean_str(line))\n",
    "train_data = np.concatenate((train_pos, train_neg))\n",
    "\n",
    "pos_labels = np.ones(len(train_pos))\n",
    "neg_labels = np.zeros(len(train_neg))\n",
    "labels = np.concatenate((pos_labels, neg_labels))\n",
    "\n",
    "shuffled_indices = list(range(len(train_data)))\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "train_data = train_data[shuffled_indices]\n",
    "labels = labels[shuffled_indices]\n",
    "\n",
    "n_classes = len(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(train_data)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1\n",
    "\n",
    "embedding_size = 300\n",
    "sentence_size = 59\n",
    "X_train = tokenizer.texts_to_sequences(train_data)\n",
    "X_train = pad_sequences(X_train, maxlen=sentence_size, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reverse_word_index = {v: k for k,v in word_index.items()}\n",
    "reverse_word_index[0] = '<PAD>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_weights = []\n",
    "embedding_weights.append(list(np.zeros(embedding_size)))\n",
    "for k, v in word_index.items():\n",
    "    try:\n",
    "        wv = w2v[k]\n",
    "    except:\n",
    "        wv = np.random.random(embedding_size)\n",
    "    embedding_weights.append(list(wv))\n",
    "embedding_weights = np.array(embedding_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all datasets we use: \n",
    "rectified linear units, \n",
    "filter windows (h) of 3, 4, 5 with 100 feature maps each,\n",
    "dropout rate (p) of 0.5, \n",
    "l2 constraint (s) of 3,\n",
    "mini-batch size of 50. \n",
    "\n",
    "These values were chosen\n",
    "via a grid search on the SST-2 dev set.\n",
    "We do not otherwise perform any datasetspecific tuning other than early stopping on dev\n",
    "sets. For datasets without a standard dev set we\n",
    "randomly select 10% of the training data as the\n",
    "dev set. \n",
    "Training is done through stochastic gradient descent over shuffled mini-batches with the Adadelta update rule (Zeiler, 2012)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model outside class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define model\n",
    "\n",
    "static = True\n",
    "rand = False\n",
    "multichannel = True\n",
    "conv_n_filters = 5\n",
    "conv_filter_sizes = [3, 4, 5]\n",
    "conv_window_size = (5, embedding_size)\n",
    "pool_window_size = (4,4)\n",
    "hidden_layer_size = 32\n",
    "dropout_size = 0.5\n",
    "\n",
    "inp = Input(shape=(sentence_size,))\n",
    "if multichannel:\n",
    "    emb1 = Embedding(vocab_size, embedding_size, weights=[embedding_weights], trainable=False)(inp)\n",
    "    emb1 = Reshape((sentence_size, embedding_size, 1))(emb1)\n",
    "    emb2 = Embedding(vocab_size, embedding_size, weights=[embedding_weights], trainable=True)(inp)\n",
    "    emb2 = Reshape((sentence_size, embedding_size, 1))(emb2)\n",
    "    x = Concatenate()([emb1, emb2])\n",
    "else:\n",
    "    if rand:\n",
    "        emb = Embedding(vocab_size, embedding_size)(inp)\n",
    "    elif static:\n",
    "        emb = Embedding(vocab_size, embedding_size, weights=[embedding_weights], trainable=False)(inp)\n",
    "    else:\n",
    "        emb = Embedding(vocab_size, embedding_size, weights=[embedding_weights], trainable=True)(inp)\n",
    "    x = Reshape((sentence_size, embedding_size, 1))(emb)\n",
    "\n",
    "convolution_layer = []\n",
    "for filter_size in conv_filter_sizes:\n",
    "    conv_window_size = (filter_size, embedding_size)\n",
    "    conv = Conv2D(conv_n_filters, conv_window_size, activation='relu', use_bias=True, padding='valid')(x)\n",
    "    convolution_layer.append(GlobalMaxPooling2D()(conv))\n",
    "\n",
    "x = Concatenate()(convolution_layer)\n",
    "x = Dropout(dropout_size)(x)\n",
    "x = Dense(1, activation='sigmoid', kernel_constraint=max_norm(3))(x)\n",
    "\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "model.compile(optimizer=Adadelta(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training split 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9595 samples, validate on 1067 samples\n",
      "Epoch 1/2\n",
      "9595/9595 [==============================] - 42s 4ms/step - loss: 0.6240 - acc: 0.6522 - val_loss: 0.5533 - val_acc: 0.7245\n",
      "Epoch 2/2\n",
      "9595/9595 [==============================] - 46s 5ms/step - loss: 0.5350 - acc: 0.7375 - val_loss: 0.5301 - val_acc: 0.7132\n"
     ]
    }
   ],
   "source": [
    "### MULTICHANNEL\n",
    "#model.save_weights('model.h5')\n",
    "kf = KFold(10, random_state=42)\n",
    "histories = []\n",
    "i = 0\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    i += 1\n",
    "    train_data, test_data = X_train[train_index], X_train[test_index]\n",
    "    train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "    #model.load_weights('model.h5')\n",
    "    print(f'Training split {i}')\n",
    "    histories.append(model.fit(train_data, train_labels, validation_data=(test_data, test_labels), batch_size=32, epochs=2))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training split 1\n",
      "Train on 9595 samples, validate on 1067 samples\n",
      "Epoch 1/2\n",
      "9595/9595 [==============================] - 9s 942us/step - loss: 0.6262 - acc: 0.6486 - val_loss: 0.5556 - val_acc: 0.7366\n",
      "Epoch 2/2\n",
      "9595/9595 [==============================] - 10s 1ms/step - loss: 0.5480 - acc: 0.7294 - val_loss: 0.5302 - val_acc: 0.7310\n"
     ]
    }
   ],
   "source": [
    "### STATIC\n",
    "#model.save_weights('model.h5')\n",
    "kf = KFold(10, random_state=42)\n",
    "histories = []\n",
    "i = 0\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    i += 1\n",
    "    train_data, test_data = X_train[train_index], X_train[test_index]\n",
    "    train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "    #model.load_weights('model.h5')\n",
    "    print(f'Training split {i}')\n",
    "    histories.append(model.fit(train_data, train_labels, validation_data=(test_data, test_labels), batch_size=32, epochs=2))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training split 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9595 samples, validate on 1067 samples\n",
      "Epoch 1/2\n",
      "9595/9595 [==============================] - 33s 3ms/step - loss: 0.6256 - acc: 0.6539 - val_loss: 0.5523 - val_acc: 0.7488\n",
      "Epoch 2/2\n",
      "9595/9595 [==============================] - 31s 3ms/step - loss: 0.5398 - acc: 0.7360 - val_loss: 0.5080 - val_acc: 0.7582\n"
     ]
    }
   ],
   "source": [
    "### NON-STATIC\n",
    "#model.save_weights('model.h5')\n",
    "kf = KFold(10, random_state=42)\n",
    "histories = []\n",
    "i = 0\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    i += 1\n",
    "    train_data, test_data = X_train[train_index], X_train[test_index]\n",
    "    train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "    #model.load_weights('model.h5')\n",
    "    print(f'Training split {i}')\n",
    "    histories.append(model.fit(train_data, train_labels, validation_data=(test_data, test_labels), batch_size=32, epochs=2))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training split 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9595 samples, validate on 1067 samples\n",
      "Epoch 1/2\n",
      "9595/9595 [==============================] - 33s 3ms/step - loss: 0.6853 - acc: 0.5510 - val_loss: 0.6664 - val_acc: 0.6120\n",
      "Epoch 2/2\n",
      "9595/9595 [==============================] - 31s 3ms/step - loss: 0.6468 - acc: 0.6368 - val_loss: 0.6161 - val_acc: 0.6785\n"
     ]
    }
   ],
   "source": [
    "### RAND\n",
    "#model.save_weights('model.h5')\n",
    "kf = KFold(10, random_state=42)\n",
    "histories = []\n",
    "i = 0\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    i += 1\n",
    "    train_data, test_data = X_train[train_index], X_train[test_index]\n",
    "    train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "    #model.load_weights('model.h5')\n",
    "    print(f'Training split {i}')\n",
    "    histories.append(model.fit(train_data, train_labels, validation_data=(test_data, test_labels), batch_size=32, epochs=2))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw0U3s4ICTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'], label='train_acc')\n",
    "plt.plot(history.history['val_acc'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class CNN SENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN_Sentence():\n",
    "    def __init__(self, sentence_size, embedding_size, n_filters, filter_sizes, kernel_size, dropout_ratio, \n",
    "                 embedding_weights=None, optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']):\n",
    "        inp = Input(shape=(sentence_size,))\n",
    "        if embedding_weights is not None:\n",
    "            emb = Embedding(vocab_size, embedding_size, weights=[embedding_weights])(inp)\n",
    "        else:\n",
    "            emb = Embedding(vocab_size, embedding_size)(inp)\n",
    "        x = Reshape((sentence_size, embedding_size, 1))(emb)\n",
    "\n",
    "        convolution_layer = []\n",
    "        for filter_size in filter_sizes:\n",
    "            conv_window_size = (filter_size, embedding_size)\n",
    "            conv = Conv2D(n_filters, kernel_size, activation='relu', use_bias=True, padding='valid')(x)\n",
    "            convolution_layer.append(GlobalMaxPooling2D()(conv))\n",
    "\n",
    "        x = Concatenate()(convolution_layer)\n",
    "        x = Dropout(dropout_ratio)(x)\n",
    "        x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        self._model = Model(inputs=inp, outputs=x)\n",
    "        self._model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "        \n",
    "    def fit(self, x, y, batch_size=32, epochs=5):\n",
    "        self._history = self._model.fit(x, y, batch_size, epochs)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        self._model.predict(x)\n",
    "        \n",
    "    def summary(self):\n",
    "        print(self._model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_Sentence(sentence_size=sentence_size, embedding_size=300, n_filters=5, filter_sizes=[3,4,5], \n",
    "                     kernel_size=[5,embedding_size], dropout_ratio=0.5, embedding_weights=embedding_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10662/10662 [==============================] - 34s 3ms/step - loss: 0.5686 - acc: 0.7077\n",
      "Epoch 2/5\n",
      "10662/10662 [==============================] - 31s 3ms/step - loss: 0.3985 - acc: 0.8341\n",
      "Epoch 3/5\n",
      "10662/10662 [==============================] - 34s 3ms/step - loss: 0.2630 - acc: 0.9009\n",
      "Epoch 4/5\n",
      "10662/10662 [==============================] - 32s 3ms/step - loss: 0.1815 - acc: 0.9363\n",
      "Epoch 5/5\n",
      "10662/10662 [==============================] - 33s 3ms/step - loss: 0.1228 - acc: 0.9609\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using \"same\" padding results in the training being veeeeery slow. <br>\n",
    "TF optimizers are not working properly and don't converge. However, Keras optimizers run into a denser tensor problem, which may impact performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
